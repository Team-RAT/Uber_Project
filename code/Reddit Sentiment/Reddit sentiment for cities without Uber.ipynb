{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json #read json\n",
    "from pprint import pprint  # will import in nice way (from folder import function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def redditupload(url_list):\n",
    "    tweets = []\n",
    "    for url in url_list:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            html = response.read()\n",
    "        htmld = json.loads(html)\n",
    "\n",
    "        for comment in htmld[1]['data']['children']:\n",
    "            #print(comment['data']['body'])\n",
    "            sent = analyser.polarity_scores(comment['data']['body'])['compound']\n",
    "            tweets.append(sent)\n",
    "\n",
    "            replies = comment['data']['replies'] #['children'][0]['data']\n",
    "\n",
    "        #for i in list(range(len(replies['data']['children']))):\n",
    "            while replies !=\"\":\n",
    "                #print(replies['data']['children'][0]['data']['body'])\n",
    "                sent1 = analyser.polarity_scores(replies['data']['children'][0]['data']['body'])['compound']\n",
    "                replies = replies['data']['children'][0]['data']['replies']\n",
    "                #sent = analyser.polarity_scores(more)['compound']\n",
    "                tweets.append(sent1)\n",
    "                #print('')\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aberdeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [r'https://www.reddit.com/r/Aberdeen/comments/6vu4cf/are_there_any_ride_share_programs_in_aberdeen/.json'\\\n",
    ",r'https://www.reddit.com/r/Aberdeen/comments/5kn60o/why_so_few_taxis/.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "aberdeen=redditupload(urls)\n",
    "aberdeen_avg = np.average(aberdeen)\n",
    "aberdeen_count=len(aberdeen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1027,\n",
       " 0.0,\n",
       " 0.7184,\n",
       " 0.0,\n",
       " -0.6786,\n",
       " 0.3182,\n",
       " 0.7906,\n",
       " 0.3612,\n",
       " 0.6124,\n",
       " 0.0,\n",
       " 0.2732,\n",
       " -0.296,\n",
       " 0.4019,\n",
       " -0.7579,\n",
       " 0.0772,\n",
       " -0.4491,\n",
       " 0.8591,\n",
       " 0.3612,\n",
       " 0.0,\n",
       " 0.565,\n",
       " -0.4215,\n",
       " 0.7351,\n",
       " 0.719]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aberdeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aberdeen', 0.17768260869565219, 23]]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.append(['Aberdeen',aberdeen_avg,aberdeen_count])\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=[r'https://www.reddit.com/r/Bath/comments/3lyis2/uber_to_come_to_bath/.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5423, 0.6808, 0.0, 0.0, 0.8258, 0.0, 0.4215, 0.3818]\n"
     ]
    }
   ],
   "source": [
    "bath = redditupload(url1)\n",
    "print(bath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_avg = np.average(bath)\n",
    "bath_count=len(bath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aberdeen', 0.17768260869565219, 23], ['Bath', 0.22094999999999998, 8]]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.append(['Bath',bath_avg,bath_count])\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url2=[r'https://www.reddit.com/r/oxford/comments/6lrrqk/oxford_taxis/.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxford = redditupload(url2)\n",
    "oxford_avg = np.average(oxford)\n",
    "oxford_count=len(oxford)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5667, 0.8605, 0.6808, 0.2732, 0.4404, -0.0332, -0.4814, 0.7227, 0.2944]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aberdeen', 0.17768260869565219, 23],\n",
       " ['Bath', 0.22094999999999998, 8],\n",
       " ['Oxford', 0.36934444444444448, 9]]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities.append(['Oxford',oxford_avg,oxford_count])\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print (string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [''.join(c for c in s if c not in string.punctuation) for s in reddit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nah the local taxi drivers go into absolute melt down every time its mentioned',\n",
       " 'Uber in Aberdeenhttpssmediacacheak0pinimgcom736xf3aa3ff3aa3ff2413b9f87ebd98ce6c0f32e8bsmellgoodimpressionjpg',\n",
       " 'A spokeswoman for Uber said “Uber’s ambition is to be everywhere – any progressive forwardthinking city – that has a need for safe reliable and efficient transportation we want to be there\\n\\nI wont hold my breath ',\n",
       " 'Nothing as far as Im aware I believe Uber have said they plan to come to Aberdeen but not time has been set as far as I know',\n",
       " 'In Aberdeen all the uber drivers must have either a private hire or taxi licences with the council from this year requiring all private hire drivers to have the hackney test uber is dead in the water',\n",
       " 'Sure UBER have said they need a minimum of 100 drivers to sign up Then they will start the service in that city ',\n",
       " 'They base potential locations on how many people download their app in the area The initial interest in Aberdeen came from a fair few people downloading the app clearly not enough though',\n",
       " 'Uber I heard from someone that they had plans to release it in Aberdeen this summer but I dont think there was enough interest \\n',\n",
       " 'Theres this httpsliftsharecomukjourneysfromaberdeenunitedkingdom but its more of a commuting thing Related httpsliftsharecomukcommunitygetabout']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "reddit = []\n",
    "for i in htmld[1]['data']['children']:\n",
    "    #print(i['data']['body'])\n",
    "    p = (i['data']['body'])\n",
    "    sent = analyser.polarity_scores(p)['compound']\n",
    "    reddit.append(sent)\n",
    "    if  i['data']['replies'] !=\"\":\n",
    "        #pprint(i['data']['replies']['data']['children'][0]['data']['body'])\n",
    "        t =(i['data']['replies']['data']['children'][0]['data']['body'])\n",
    "        reddit.append(t)\n",
    "    else:\n",
    "        print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2732,\n",
       " 'No drinking in town. Stood at a rank with about 50 people. Maybe four taxis appeared in 30 minutes, mental.',\n",
       " 0.0772,\n",
       " \"Because at 3am, all taxis in Aberdeen are usually busy and won't be available if you call, hence why there are none waiting at taxi ranks.\\n\\nIt's an awful city for taxis, they are way overpriced and hardly ever available when you most need them (weekend evenings and weekday mornings). Never had this problem in other cities. \\n\\nThe sooner we get Uber the better. \",\n",
       " 0.3612,\n",
       " 'Ask the council why rates in Aberdeen are so high compared to the rest of the country...',\n",
       " 0.565,\n",
       " '&gt; There used to be loads of taxis, but since the oil industry downturn\\n\\nJust no.\\n\\nI\\'ve been a regular in town for coming on 10 years and it\\'s got bugger all to do with a downturn, there also has never been \"loads of taxis\".\\n\\nEven during an oil boom where everyone has plenty of spare cash Taxi Rank queues are incredibly long, to the point i don\\'t wait in them anymore as i can walk home in about 45 minutes, which is shorter than the amount of time it takes to even get near the front of the queue.',\n",
       " 0.719]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you mean by the station? Apparently only certain taxis are allowed in there. A Rainbow City driver told me he got called some choice words when he went in there.\n",
      "No drinking in town. Stood at a rank with about 50 people. Maybe four taxis appeared in 30 minutes, mental.\n",
      "\n",
      "That's because taxis tend to stop for people who flag them down on Union Street before getting to the taxi rank. \n",
      "\n",
      "I stand 100 metres or so before the taxi rank, never have to wait more than 5 minutes for a taxi to pull over. No point being a martyr if everyone else is going to do it.\n",
      "\n",
      "Alternatively, it's also easy to flag them down on King Street or Albyn Place as they're on their way back into town after dropping off their last fare.\n",
      "\n",
      "What surprises me most is that the night buses only run once an hour. I'm sure more people would use them if they were more frequent, reducing the dependency on taxis. \n",
      "\n",
      "Thats unusual as there is a cabby code of conduct stating where they can pickup and when.  You don't pickup on union street unless stopped at a rank. Otherwise the same shit happens as happens to strike breakers during a strike\n",
      "\n",
      "Why wait at the taxi rank? Whenever I need a taxi I phone a taxi number and give them a nearby address. Or just ask to get picked up outside the theatre. Always get one. Have never waited at the taxi rank.\n",
      "Because at 3am, all taxis in Aberdeen are usually busy and won't be available if you call, hence why there are none waiting at taxi ranks.\n",
      "\n",
      "It's an awful city for taxis, they are way overpriced and hardly ever available when you most need them (weekend evenings and weekday mornings). Never had this problem in other cities. \n",
      "\n",
      "The sooner we get Uber the better. \n",
      "\n",
      "Well maybe I'm just lucky then. As I stated, always phone and get one to pick me up at an address or the theatre. Even after club closing time. Maybe I'm on record as a tipper, surely they keep that stuff on record? Would be interesting to see.\n",
      "\n",
      "The council licence the taxis, agree the numbers and set the rate.\n",
      "\n",
      "Ask the council why there are not enough taxis.\n",
      "Ask the council why rates in Aberdeen are so high compared to the rest of the country...\n",
      "\n",
      "Since when have you been visiting? There used to be loads of taxis, but since the oil industry downturn, taxi driving isn't as profitable. \n",
      "And if it is holiday time (now) there aren't even any students around, so drivers might not think it worth going out?\n",
      "Just guessing. \n",
      "Hope a taxi driver answers.\n",
      "&gt; There used to be loads of taxis, but since the oil industry downturn\n",
      "\n",
      "Just no.\n",
      "\n",
      "I've been a regular in town for coming on 10 years and it's got bugger all to do with a downturn, there also has never been \"loads of taxis\".\n",
      "\n",
      "Even during an oil boom where everyone has plenty of spare cash Taxi Rank queues are incredibly long, to the point i don't wait in them anymore as i can walk home in about 45 minutes, which is shorter than the amount of time it takes to even get near the front of the queue.\n",
      "\n",
      "Yeah probably ten years ago was my first visit and honestly i thought there was a strike or something. Seemed like reams of people queuing in union street for an eon. \n",
      "\n",
      "I have 5 friends who are taxi drivers and they are barely profitable.  There are too many taxis for too few passengers - people are more willing to walk due to not having as much money because of wage cuts and unemployment.  The drivers tend to swarm the ranks in hope of getting the slim pickings so there aren't many drivers \"floating\" about which makes it seem like there are less.\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "for comment in htmld[1]['data']['children']:\n",
    "    print(comment['data']['body'])\n",
    "    sent = analyser.polarity_scores(comment['data']['body'])['compound']\n",
    "    tweets.append(sent)\n",
    "    \n",
    "    replies = comment['data']['replies'] #['children'][0]['data']\n",
    "    \n",
    "#for i in list(range(len(replies['data']['children']))):\n",
    "    while replies !=\"\":\n",
    "        print(replies['data']['children'][0]['data']['body'])\n",
    "        sent1 = analyser.polarity_scores(replies['data']['children'][0]['data']['body'])['compound']\n",
    "        replies = replies['data']['children'][0]['data']['replies']\n",
    "        #sent = analyser.polarity_scores(more)['compound']\n",
    "        tweets.append(sent1)\n",
    "        print('')\n",
    "        #pprint(i['data']['replies']['data']['children'][0]['data']['body'])\n",
    "    \n",
    "#     p=(i['data']['body'])\n",
    "#     listbrexit.append(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
